{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract prediction value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning.rate</th>\n",
       "      <th>L1.regularization</th>\n",
       "      <th>training.steps</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>execution.time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>8.079377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>7.283534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>5.555197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>7.278638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>16.311707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout  learning.rate  L1.regularization  training.steps  accuracy  \\\n",
       "0     0.01         0.0002               0.01             100  0.466667   \n",
       "1     0.01         0.0002               0.01             500  0.466667   \n",
       "2     0.01         0.0002               0.01            2500  0.266667   \n",
       "3     0.01         0.0002               0.10             100  0.266667   \n",
       "4     0.01         0.0002               0.10             500  0.466667   \n",
       "\n",
       "   execution.time  \n",
       "0        8.079377  \n",
       "1        7.283534  \n",
       "2        5.555197  \n",
       "3        7.278638  \n",
       "4       16.311707  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sigmoid = pd.read_csv('Sigmoid_data.csv', usecols=['dropout', 'learning.rate', 'L1.regularization', 'training.steps', 'accuracy', 'execution.time'])\n",
    "df_sigmoid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicted Quality\n",
    "def pred_quality(x):\n",
    "    if x < 0.5:\n",
    "        return 0\n",
    "    elif (x >= 0.5 and x < 0.8):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df_sigmoid['Prediction'] = df_sigmoid['accuracy'].apply(pred_quality)\n",
    "df_sigmoid.to_csv('Sigmoid_data_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning.rate</th>\n",
       "      <th>L1.regularization</th>\n",
       "      <th>training.steps</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>execution.time</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>8.079377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>7.283534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>5.555197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>7.278638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>16.311707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout  learning.rate  L1.regularization  training.steps  accuracy  \\\n",
       "0     0.01         0.0002               0.01             100  0.466667   \n",
       "1     0.01         0.0002               0.01             500  0.466667   \n",
       "2     0.01         0.0002               0.01            2500  0.266667   \n",
       "3     0.01         0.0002               0.10             100  0.266667   \n",
       "4     0.01         0.0002               0.10             500  0.466667   \n",
       "\n",
       "   execution.time  Prediction  \n",
       "0        8.079377           0  \n",
       "1        7.283534           0  \n",
       "2        5.555197           0  \n",
       "3        7.278638           0  \n",
       "4       16.311707           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sigmoid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dropout',\n",
       " 'learning.rate',\n",
       " 'L1.regularization',\n",
       " 'training.steps',\n",
       " 'accuracy',\n",
       " 'execution.time',\n",
       " 'Prediction']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = list(df_sigmoid.columns)\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning.rate</th>\n",
       "      <th>L1.regularization</th>\n",
       "      <th>training.steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.10</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout  learning.rate  L1.regularization  training.steps\n",
       "0     0.01         0.0002               0.01             100\n",
       "1     0.01         0.0002               0.01             500\n",
       "2     0.01         0.0002               0.01            2500\n",
       "3     0.01         0.0002               0.10             100\n",
       "4     0.01         0.0002               0.10             500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_sigmoid[lst[0:4]]\n",
    "y = df_sigmoid['Prediction']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(max_iter=10000, C=100, tol=0.0000001, solver='sag', multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning.rate</th>\n",
       "      <th>L1.regularization</th>\n",
       "      <th>training.steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>10.00</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>10.00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>10.00</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>1.00</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>0.10</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>1.00</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>1.00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>10.00</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.10</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>10.00</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>1.00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>10.00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.10</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>1.00</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>1.00</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>10.00</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>10.00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>10.00</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>1.00</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.10</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>1.00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>10.00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>10.00</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>0.10</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>1.00</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.10</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>10.00</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.10</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>10.00</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dropout  learning.rate  L1.regularization  training.steps\n",
       "284     0.25         0.2048               1.00            2500\n",
       "95      0.05         0.0008              10.00            2500\n",
       "213     0.10         0.2048              10.00             100\n",
       "35      0.01         0.0032              10.00            2500\n",
       "231     0.25         0.0008               0.10             100\n",
       "38      0.01         0.0128               0.01            2500\n",
       "265     0.25         0.0512               0.01             500\n",
       "199     0.10         0.0512               1.00             500\n",
       "281     0.25         0.2048               0.10            2500\n",
       "64      0.01         0.2048               0.10             500\n",
       "133     0.05         0.2048               0.01             500\n",
       "170     0.10         0.0032               0.01            2500\n",
       "72      0.05         0.0002               0.01             100\n",
       "247     0.25         0.0032               1.00             500\n",
       "218     0.25         0.0002               0.01            2500\n",
       "198     0.10         0.0512               1.00             100\n",
       "154     0.10         0.0002              10.00             500\n",
       "25      0.01         0.0032               0.01             500\n",
       "180     0.10         0.0128               0.01             100\n",
       "112     0.05         0.0128               0.10             500\n",
       "252     0.25         0.0128               0.01             100\n",
       "22      0.01         0.0008              10.00             500\n",
       "42      0.01         0.0128               1.00             100\n",
       "216     0.25         0.0002               0.01             100\n",
       "200     0.10         0.0512               1.00            2500\n",
       "93      0.05         0.0008              10.00             100\n",
       "121     0.05         0.0512               0.01             500\n",
       "145     0.10         0.0002               0.01             500\n",
       "88      0.05         0.0008               0.10             500\n",
       "219     0.25         0.0002               0.10             100\n",
       "..       ...            ...                ...             ...\n",
       "103     0.05         0.0032               1.00             500\n",
       "7       0.01         0.0002               1.00             500\n",
       "99      0.05         0.0032               0.10             100\n",
       "164     0.10         0.0008               1.00            2500\n",
       "62      0.01         0.2048               0.01            2500\n",
       "239     0.25         0.0008              10.00            2500\n",
       "105     0.05         0.0032              10.00             100\n",
       "107     0.05         0.0032              10.00            2500\n",
       "223     0.25         0.0002               1.00             500\n",
       "76      0.05         0.0002               0.10             500\n",
       "126     0.05         0.0512               1.00             100\n",
       "249     0.25         0.0032              10.00             100\n",
       "44      0.01         0.0128               1.00            2500\n",
       "59      0.01         0.0512              10.00            2500\n",
       "136     0.05         0.2048               0.10             500\n",
       "111     0.05         0.0128               0.10             100\n",
       "49      0.01         0.0512               0.01             500\n",
       "283     0.25         0.2048               1.00             500\n",
       "5       0.01         0.0002               0.10            2500\n",
       "110     0.05         0.0128               0.01            2500\n",
       "192     0.10         0.0512               0.01             100\n",
       "220     0.25         0.0002               0.10             500\n",
       "245     0.25         0.0032               0.10            2500\n",
       "286     0.25         0.2048              10.00             500\n",
       "132     0.05         0.2048               0.01             100\n",
       "40      0.01         0.0128               0.10             500\n",
       "75      0.05         0.0002               0.10             100\n",
       "87      0.05         0.0008               0.10             100\n",
       "63      0.01         0.2048               0.10             100\n",
       "11      0.01         0.0002              10.00            2500\n",
       "\n",
       "[192 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284    0\n",
       "95     0\n",
       "213    0\n",
       "35     0\n",
       "231    0\n",
       "38     0\n",
       "265    0\n",
       "199    2\n",
       "281    1\n",
       "64     2\n",
       "133    0\n",
       "170    0\n",
       "72     0\n",
       "247    1\n",
       "218    0\n",
       "198    1\n",
       "154    0\n",
       "25     0\n",
       "180    0\n",
       "112    2\n",
       "252    0\n",
       "22     0\n",
       "42     1\n",
       "216    0\n",
       "200    0\n",
       "93     0\n",
       "121    0\n",
       "145    0\n",
       "88     0\n",
       "219    0\n",
       "      ..\n",
       "103    1\n",
       "7      0\n",
       "99     0\n",
       "164    0\n",
       "62     2\n",
       "239    0\n",
       "105    0\n",
       "107    0\n",
       "223    0\n",
       "76     0\n",
       "126    1\n",
       "249    0\n",
       "44     0\n",
       "59     0\n",
       "136    2\n",
       "111    1\n",
       "49     0\n",
       "283    0\n",
       "5      0\n",
       "110    1\n",
       "192    0\n",
       "220    0\n",
       "245    0\n",
       "286    0\n",
       "132    0\n",
       "40     2\n",
       "75     0\n",
       "87     0\n",
       "63     2\n",
       "11     0\n",
       "Name: Prediction, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 0.0990991 , 1.        ],\n",
       "       [0.16666667, 0.00293255, 1.        , 1.        ],\n",
       "       [0.375     , 1.        , 1.        , 0.        ],\n",
       "       [0.        , 0.01466276, 1.        , 1.        ],\n",
       "       [1.        , 0.00293255, 0.00900901, 0.        ],\n",
       "       [0.        , 0.06158358, 0.        , 1.        ],\n",
       "       [1.        , 0.24926686, 0.        , 0.16666667],\n",
       "       [0.375     , 0.24926686, 0.0990991 , 0.16666667],\n",
       "       [1.        , 1.        , 0.00900901, 1.        ],\n",
       "       [0.        , 1.        , 0.00900901, 0.16666667],\n",
       "       [0.16666667, 1.        , 0.        , 0.16666667],\n",
       "       [0.375     , 0.01466276, 0.        , 1.        ],\n",
       "       [0.16666667, 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.01466276, 0.0990991 , 0.16666667],\n",
       "       [1.        , 0.        , 0.        , 1.        ],\n",
       "       [0.375     , 0.24926686, 0.0990991 , 0.        ],\n",
       "       [0.375     , 0.        , 1.        , 0.16666667],\n",
       "       [0.        , 0.01466276, 0.        , 0.16666667],\n",
       "       [0.375     , 0.06158358, 0.        , 0.        ],\n",
       "       [0.16666667, 0.06158358, 0.00900901, 0.16666667],\n",
       "       [1.        , 0.06158358, 0.        , 0.        ],\n",
       "       [0.        , 0.00293255, 1.        , 0.16666667],\n",
       "       [0.        , 0.06158358, 0.0990991 , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.375     , 0.24926686, 0.0990991 , 1.        ],\n",
       "       [0.16666667, 0.00293255, 1.        , 0.        ],\n",
       "       [0.16666667, 0.24926686, 0.        , 0.16666667],\n",
       "       [0.375     , 0.        , 0.        , 0.16666667],\n",
       "       [0.16666667, 0.00293255, 0.00900901, 0.16666667],\n",
       "       [1.        , 0.        , 0.00900901, 0.        ],\n",
       "       [0.        , 0.24926686, 0.        , 1.        ],\n",
       "       [0.16666667, 0.        , 0.0990991 , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.24926686, 0.0990991 , 0.        ],\n",
       "       [0.        , 1.        , 0.0990991 , 0.        ],\n",
       "       [1.        , 0.24926686, 0.00900901, 0.        ],\n",
       "       [1.        , 0.        , 1.        , 1.        ],\n",
       "       [0.375     , 0.06158358, 0.0990991 , 0.        ],\n",
       "       [0.16666667, 0.01466276, 0.        , 0.        ],\n",
       "       [1.        , 0.01466276, 1.        , 1.        ],\n",
       "       [1.        , 0.00293255, 0.0990991 , 0.16666667],\n",
       "       [0.375     , 1.        , 0.00900901, 0.16666667],\n",
       "       [0.375     , 0.06158358, 0.0990991 , 0.16666667],\n",
       "       [0.375     , 0.06158358, 1.        , 0.        ],\n",
       "       [0.375     , 0.01466276, 0.        , 0.        ],\n",
       "       [0.375     , 1.        , 0.        , 1.        ],\n",
       "       [0.        , 0.24926686, 0.00900901, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.16666667],\n",
       "       [0.        , 1.        , 0.0990991 , 1.        ],\n",
       "       [0.16666667, 0.        , 0.0990991 , 0.16666667],\n",
       "       [0.16666667, 0.24926686, 1.        , 0.        ],\n",
       "       [0.        , 0.06158358, 0.0990991 , 0.16666667],\n",
       "       [0.        , 1.        , 0.0990991 , 0.16666667],\n",
       "       [0.375     , 0.00293255, 1.        , 1.        ],\n",
       "       [0.16666667, 0.24926686, 0.00900901, 1.        ],\n",
       "       [1.        , 0.01466276, 0.0990991 , 0.        ],\n",
       "       [0.        , 0.06158358, 0.        , 0.        ],\n",
       "       [1.        , 0.01466276, 0.        , 1.        ],\n",
       "       [1.        , 0.01466276, 0.00900901, 0.16666667],\n",
       "       [0.        , 0.06158358, 1.        , 0.        ],\n",
       "       [1.        , 0.24926686, 1.        , 1.        ],\n",
       "       [0.375     , 1.        , 1.        , 1.        ],\n",
       "       [0.        , 0.24926686, 0.00900901, 1.        ],\n",
       "       [0.375     , 0.24926686, 0.        , 1.        ],\n",
       "       [0.375     , 1.        , 0.        , 0.        ],\n",
       "       [0.16666667, 0.06158358, 0.0990991 , 0.        ],\n",
       "       [1.        , 1.        , 0.00900901, 0.16666667],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.375     , 0.        , 0.00900901, 0.16666667],\n",
       "       [0.        , 0.01466276, 0.        , 0.        ],\n",
       "       [0.16666667, 1.        , 1.        , 0.        ],\n",
       "       [0.        , 0.24926686, 0.00900901, 0.16666667],\n",
       "       [1.        , 0.        , 1.        , 0.16666667],\n",
       "       [0.375     , 0.01466276, 1.        , 0.        ],\n",
       "       [0.375     , 0.01466276, 0.00900901, 0.16666667],\n",
       "       [0.16666667, 1.        , 1.        , 0.16666667],\n",
       "       [0.375     , 0.06158358, 0.00900901, 0.        ],\n",
       "       [0.375     , 0.06158358, 1.        , 0.16666667],\n",
       "       [0.16666667, 0.01466276, 0.0990991 , 0.        ],\n",
       "       [0.16666667, 0.        , 0.00900901, 1.        ],\n",
       "       [0.375     , 0.24926686, 0.        , 0.16666667],\n",
       "       [1.        , 0.24926686, 1.        , 0.16666667],\n",
       "       [1.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.01466276, 0.00900901, 0.        ],\n",
       "       [1.        , 0.00293255, 0.00900901, 0.16666667],\n",
       "       [0.16666667, 0.01466276, 0.00900901, 0.16666667],\n",
       "       [0.16666667, 0.00293255, 1.        , 0.16666667],\n",
       "       [0.16666667, 0.24926686, 0.0990991 , 0.16666667],\n",
       "       [0.        , 0.00293255, 1.        , 1.        ],\n",
       "       [0.        , 0.00293255, 1.        , 0.        ],\n",
       "       [1.        , 0.00293255, 0.        , 0.        ],\n",
       "       [0.375     , 0.        , 0.00900901, 1.        ],\n",
       "       [0.        , 0.01466276, 0.00900901, 1.        ],\n",
       "       [1.        , 0.06158358, 1.        , 1.        ],\n",
       "       [0.16666667, 0.24926686, 1.        , 1.        ],\n",
       "       [0.        , 0.06158358, 1.        , 0.16666667],\n",
       "       [0.375     , 0.06158358, 0.00900901, 1.        ],\n",
       "       [0.16666667, 0.        , 1.        , 0.16666667],\n",
       "       [0.375     , 1.        , 0.0990991 , 1.        ],\n",
       "       [0.375     , 0.        , 0.0990991 , 0.16666667],\n",
       "       [0.16666667, 0.01466276, 0.00900901, 1.        ],\n",
       "       [0.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 0.        , 0.16666667],\n",
       "       [1.        , 0.00293255, 0.00900901, 1.        ],\n",
       "       [0.        , 0.        , 0.0990991 , 0.        ],\n",
       "       [0.375     , 0.01466276, 1.        , 1.        ],\n",
       "       [0.16666667, 0.24926686, 0.        , 0.        ],\n",
       "       [0.375     , 1.        , 0.        , 0.16666667],\n",
       "       [1.        , 0.00293255, 0.0990991 , 0.        ],\n",
       "       [0.375     , 0.24926686, 0.00900901, 1.        ],\n",
       "       [0.        , 0.00293255, 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.0990991 , 1.        ],\n",
       "       [0.16666667, 0.00293255, 0.        , 0.        ],\n",
       "       [0.16666667, 0.        , 1.        , 1.        ],\n",
       "       [0.        , 0.        , 0.00900901, 0.        ],\n",
       "       [0.        , 0.01466276, 0.00900901, 0.16666667],\n",
       "       [1.        , 0.00293255, 1.        , 0.        ],\n",
       "       [0.16666667, 0.06158358, 0.00900901, 1.        ],\n",
       "       [0.16666667, 1.        , 0.0990991 , 0.        ],\n",
       "       [0.16666667, 1.        , 0.0990991 , 0.16666667],\n",
       "       [0.16666667, 0.00293255, 0.0990991 , 1.        ],\n",
       "       [0.        , 0.24926686, 1.        , 0.16666667],\n",
       "       [0.375     , 0.        , 0.        , 1.        ],\n",
       "       [0.16666667, 0.24926686, 1.        , 0.16666667],\n",
       "       [0.375     , 0.01466276, 0.00900901, 1.        ],\n",
       "       [0.16666667, 1.        , 0.00900901, 1.        ],\n",
       "       [0.375     , 1.        , 1.        , 0.16666667],\n",
       "       [0.375     , 0.06158358, 0.        , 1.        ],\n",
       "       [0.        , 0.06158358, 1.        , 1.        ],\n",
       "       [0.375     , 0.01466276, 0.0990991 , 0.        ],\n",
       "       [1.        , 1.        , 1.        , 0.        ],\n",
       "       [0.        , 0.01466276, 0.        , 1.        ],\n",
       "       [0.16666667, 0.24926686, 0.        , 1.        ],\n",
       "       [0.16666667, 0.00293255, 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.0990991 , 1.        ],\n",
       "       [0.375     , 0.        , 1.        , 1.        ],\n",
       "       [0.        , 0.00293255, 0.0990991 , 1.        ],\n",
       "       [1.        , 0.06158358, 0.00900901, 0.16666667],\n",
       "       [0.375     , 0.06158358, 0.0990991 , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.16666667],\n",
       "       [0.        , 0.01466276, 0.0990991 , 0.        ],\n",
       "       [0.375     , 0.00293255, 0.0990991 , 0.16666667],\n",
       "       [0.        , 0.00293255, 0.0990991 , 0.16666667],\n",
       "       [0.375     , 0.06158358, 1.        , 1.        ],\n",
       "       [0.16666667, 0.24926686, 0.00900901, 0.16666667],\n",
       "       [1.        , 0.06158358, 1.        , 0.        ],\n",
       "       [0.375     , 0.        , 0.0990991 , 1.        ],\n",
       "       [1.        , 0.        , 0.00900901, 1.        ],\n",
       "       [0.16666667, 0.01466276, 0.        , 0.16666667],\n",
       "       [0.375     , 1.        , 0.00900901, 0.        ],\n",
       "       [1.        , 0.01466276, 0.00900901, 0.        ],\n",
       "       [0.375     , 0.24926686, 1.        , 1.        ],\n",
       "       [1.        , 0.01466276, 0.0990991 , 1.        ],\n",
       "       [0.        , 0.00293255, 0.00900901, 1.        ],\n",
       "       [0.16666667, 1.        , 0.0990991 , 1.        ],\n",
       "       [0.16666667, 0.01466276, 1.        , 0.16666667],\n",
       "       [0.16666667, 0.06158358, 0.0990991 , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.24926686, 0.0990991 , 0.        ],\n",
       "       [0.16666667, 1.        , 1.        , 1.        ],\n",
       "       [1.        , 0.06158358, 0.0990991 , 0.        ],\n",
       "       [1.        , 0.00293255, 1.        , 0.16666667],\n",
       "       [0.16666667, 0.01466276, 0.0990991 , 0.16666667],\n",
       "       [0.        , 0.        , 0.0990991 , 0.16666667],\n",
       "       [0.16666667, 0.01466276, 0.00900901, 0.        ],\n",
       "       [0.375     , 0.00293255, 0.0990991 , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 1.        ],\n",
       "       [1.        , 0.00293255, 1.        , 1.        ],\n",
       "       [0.16666667, 0.01466276, 1.        , 0.        ],\n",
       "       [0.16666667, 0.01466276, 1.        , 1.        ],\n",
       "       [1.        , 0.        , 0.0990991 , 0.16666667],\n",
       "       [0.16666667, 0.        , 0.00900901, 0.16666667],\n",
       "       [0.16666667, 0.24926686, 0.0990991 , 0.        ],\n",
       "       [1.        , 0.01466276, 1.        , 0.        ],\n",
       "       [0.        , 0.06158358, 0.0990991 , 1.        ],\n",
       "       [0.        , 0.24926686, 1.        , 1.        ],\n",
       "       [0.16666667, 1.        , 0.00900901, 0.16666667],\n",
       "       [0.16666667, 0.06158358, 0.00900901, 0.        ],\n",
       "       [0.        , 0.24926686, 0.        , 0.16666667],\n",
       "       [1.        , 1.        , 0.0990991 , 0.16666667],\n",
       "       [0.        , 0.        , 0.00900901, 1.        ],\n",
       "       [0.16666667, 0.06158358, 0.        , 1.        ],\n",
       "       [0.375     , 0.24926686, 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.00900901, 0.16666667],\n",
       "       [1.        , 0.01466276, 0.00900901, 1.        ],\n",
       "       [1.        , 1.        , 1.        , 0.16666667],\n",
       "       [0.16666667, 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.06158358, 0.00900901, 0.16666667],\n",
       "       [0.16666667, 0.        , 0.00900901, 0.        ],\n",
       "       [0.16666667, 0.00293255, 0.00900901, 0.        ],\n",
       "       [0.        , 1.        , 0.00900901, 0.        ],\n",
       "       [0.        , 0.        , 1.        , 1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=10000, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='sag',\n",
       "          tol=1e-07, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = log_model.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Low</th>\n",
       "      <th>Predicted Medium</th>\n",
       "      <th>Predicted High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Low</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Medium</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True High</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted Low  Predicted Medium  Predicted High\n",
       "True Low                70                 0               1\n",
       "True Medium             16                 0               0\n",
       "True High                8                 0               1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf = pd.DataFrame(data=confusion_matrix(y_test, y_pred), \n",
    "                    columns=['Predicted Low', 'Predicted Medium', 'Predicted High'], \n",
    "                    index=['True Low','True Medium','True High'])\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Low       0.74      0.99      0.85        71\n",
      "     Medium       0.00      0.00      0.00        16\n",
      "       High       0.50      0.11      0.18         9\n",
      "\n",
      "avg / total       0.60      0.74      0.64        96\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\StrikeWade\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['Low', 'Medium', 'High']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\StrikeWade\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_VLOG_LEVEL'] = '2'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from tensorflow import logging\n",
    "logging.set_verbosity(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into train and test csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(data, test_size):\n",
    "    data_file = data\n",
    "    df = pd.read_csv(data, usecols=['dropout', 'learning.rate', 'L1.regularization', 'training.steps','Prediction'])\n",
    "    df_train, df_test = train_test_split(df, test_size=0.33, random_state=101)\n",
    "    \n",
    "    name = str(data_file).split('.')[0]\n",
    "    name_train = name + '_train.csv'\n",
    "    name_test = name + '_test.csv'\n",
    "    df_train.to_csv(name_train, index=False, header=False)\n",
    "    df_test.to_csv(name_test, index=False, header=False)\n",
    "    return (df_train, df_test)\n",
    "\n",
    "sigmoid_train, sigmoid_test = split_dataset('Sigmoid_data_prediction.csv', test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = tf.contrib.learn.datasets.base.load_csv_without_header(filename='Sigmoid_data_prediction_train.csv', \n",
    "                                                                      target_dtype=np.int, \n",
    "                                                                      features_dtype=np.float64, \n",
    "                                                                      target_column=-1)\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv_without_header(filename='Sigmoid_data_prediction_test.csv', \n",
    "                                                                      target_dtype=np.int, \n",
    "                                                                      features_dtype=np.float64, \n",
    "                                                                      target_column=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(data=array([[2.500e-01, 2.048e-01, 1.000e+00, 2.500e+03],\n",
       "       [5.000e-02, 8.000e-04, 1.000e+01, 2.500e+03],\n",
       "       [1.000e-01, 2.048e-01, 1.000e+01, 1.000e+02],\n",
       "       [1.000e-02, 3.200e-03, 1.000e+01, 2.500e+03],\n",
       "       [2.500e-01, 8.000e-04, 1.000e-01, 1.000e+02],\n",
       "       [1.000e-02, 1.280e-02, 1.000e-02, 2.500e+03],\n",
       "       [2.500e-01, 5.120e-02, 1.000e-02, 5.000e+02],\n",
       "       [1.000e-01, 5.120e-02, 1.000e+00, 5.000e+02],\n",
       "       [2.500e-01, 2.048e-01, 1.000e-01, 2.500e+03],\n",
       "       [1.000e-02, 2.048e-01, 1.000e-01, 5.000e+02],\n",
       "       [5.000e-02, 2.048e-01, 1.000e-02, 5.000e+02],\n",
       "       [1.000e-01, 3.200e-03, 1.000e-02, 2.500e+03],\n",
       "       [5.000e-02, 2.000e-04, 1.000e-02, 1.000e+02],\n",
       "       [2.500e-01, 3.200e-03, 1.000e+00, 5.000e+02],\n",
       "       [2.500e-01, 2.000e-04, 1.000e-02, 2.500e+03],\n",
       "       [1.000e-01, 5.120e-02, 1.000e+00, 1.000e+02],\n",
       "       [1.000e-01, 2.000e-04, 1.000e+01, 5.000e+02],\n",
       "       [1.000e-02, 3.200e-03, 1.000e-02, 5.000e+02],\n",
       "       [1.000e-01, 1.280e-02, 1.000e-02, 1.000e+02],\n",
       "       [5.000e-02, 1.280e-02, 1.000e-01, 5.000e+02],\n",
       "       [2.500e-01, 1.280e-02, 1.000e-02, 1.000e+02],\n",
       "       [1.000e-02, 8.000e-04, 1.000e+01, 5.000e+02],\n",
       "       [1.000e-02, 1.280e-02, 1.000e+00, 1.000e+02],\n",
       "       [2.500e-01, 2.000e-04, 1.000e-02, 1.000e+02],\n",
       "       [1.000e-01, 5.120e-02, 1.000e+00, 2.500e+03],\n",
       "       [5.000e-02, 8.000e-04, 1.000e+01, 1.000e+02],\n",
       "       [5.000e-02, 5.120e-02, 1.000e-02, 5.000e+02],\n",
       "       [1.000e-01, 2.000e-04, 1.000e-02, 5.000e+02],\n",
       "       [5.000e-02, 8.000e-04, 1.000e-01, 5.000e+02],\n",
       "       [2.500e-01, 2.000e-04, 1.000e-01, 1.000e+02],\n",
       "       [1.000e-02, 5.120e-02, 1.000e-02, 2.500e+03],\n",
       "       [5.000e-02, 2.000e-04, 1.000e+00, 2.500e+03],\n",
       "       [1.000e-02, 2.000e-04, 1.000e-02, 2.500e+03],\n",
       "       [1.000e-02, 5.120e-02, 1.000e+00, 1.000e+02],\n",
       "       [1.000e-02, 2.048e-01, 1.000e+00, 1.000e+02],\n",
       "       [2.500e-01, 5.120e-02, 1.000e-01, 1.000e+02],\n",
       "       [2.500e-01, 2.000e-04, 1.000e+01, 2.500e+03],\n",
       "       [1.000e-01, 1.280e-02, 1.000e+00, 1.000e+02],\n",
       "       [5.000e-02, 3.200e-03, 1.000e-02, 1.000e+02],\n",
       "       [2.500e-01, 3.200e-03, 1.000e+01, 2.500e+03],\n",
       "       [2.500e-01, 8.000e-04, 1.000e+00, 5.000e+02],\n",
       "       [1.000e-01, 2.048e-01, 1.000e-01, 5.000e+02],\n",
       "       [1.000e-01, 1.280e-02, 1.000e+00, 5.000e+02],\n",
       "       [1.000e-01, 1.280e-02, 1.000e+01, 1.000e+02],\n",
       "       [1.000e-01, 3.200e-03, 1.000e-02, 1.000e+02],\n",
       "       [1.000e-01, 2.048e-01, 1.000e-02, 2.500e+03],\n",
       "       [1.000e-02, 5.120e-02, 1.000e-01, 1.000e+02],\n",
       "       [1.000e-02, 2.048e-01, 1.000e-02, 5.000e+02],\n",
       "       [1.000e-02, 2.048e-01, 1.000e+00, 2.500e+03],\n",
       "       [5.000e-02, 2.000e-04, 1.000e+00, 5.000e+02],\n",
       "       [5.000e-02, 5.120e-02, 1.000e+01, 1.000e+02],\n",
       "       [1.000e-02, 1.280e-02, 1.000e+00, 5.000e+02],\n",
       "       [1.000e-02, 2.048e-01, 1.000e+00, 5.000e+02],\n",
       "       [1.000e-01, 8.000e-04, 1.000e+01, 2.500e+03],\n",
       "       [5.000e-02, 5.120e-02, 1.000e-01, 2.500e+03],\n",
       "       [2.500e-01, 3.200e-03, 1.000e+00, 1.000e+02],\n",
       "       [1.000e-02, 1.280e-02, 1.000e-02, 1.000e+02],\n",
       "       [2.500e-01, 3.200e-03, 1.000e-02, 2.500e+03],\n",
       "       [2.500e-01, 3.200e-03, 1.000e-01, 5.000e+02],\n",
       "       [1.000e-02, 1.280e-02, 1.000e+01, 1.000e+02],\n",
       "       [2.500e-01, 5.120e-02, 1.000e+01, 2.500e+03],\n",
       "       [1.000e-01, 2.048e-01, 1.000e+01, 2.500e+03],\n",
       "       [1.000e-02, 5.120e-02, 1.000e-01, 2.500e+03],\n",
       "       [1.000e-01, 5.120e-02, 1.000e-02, 2.500e+03],\n",
       "       [1.000e-01, 2.048e-01, 1.000e-02, 1.000e+02],\n",
       "       [5.000e-02, 1.280e-02, 1.000e+00, 1.000e+02],\n",
       "       [2.500e-01, 2.048e-01, 1.000e-01, 5.000e+02],\n",
       "       [1.000e-02, 2.048e-01, 1.000e-02, 1.000e+02],\n",
       "       [1.000e-01, 2.000e-04, 1.000e-01, 5.000e+02],\n",
       "       [1.000e-02, 3.200e-03, 1.000e-02, 1.000e+02],\n",
       "       [5.000e-02, 2.048e-01, 1.000e+01, 1.000e+02],\n",
       "       [1.000e-02, 5.120e-02, 1.000e-01, 5.000e+02],\n",
       "       [2.500e-01, 2.000e-04, 1.000e+01, 5.000e+02],\n",
       "       [1.000e-01, 3.200e-03, 1.000e+01, 1.000e+02],\n",
       "       [1.000e-01, 3.200e-03, 1.000e-01, 5.000e+02],\n",
       "       [5.000e-02, 2.048e-01, 1.000e+01, 5.000e+02],\n",
       "       [1.000e-01, 1.280e-02, 1.000e-01, 1.000e+02],\n",
       "       [1.000e-01, 1.280e-02, 1.000e+01, 5.000e+02],\n",
       "       [5.000e-02, 3.200e-03, 1.000e+00, 1.000e+02],\n",
       "       [5.000e-02, 2.000e-04, 1.000e-01, 2.500e+03],\n",
       "       [1.000e-01, 5.120e-02, 1.000e-02, 5.000e+02],\n",
       "       [2.500e-01, 5.120e-02, 1.000e+01, 5.000e+02],\n",
       "       [2.500e-01, 2.048e-01, 1.000e-02, 1.000e+02],\n",
       "       [1.000e-02, 3.200e-03, 1.000e-01, 1.000e+02],\n",
       "       [2.500e-01, 8.000e-04, 1.000e-01, 5.000e+02],\n",
       "       [5.000e-02, 3.200e-03, 1.000e-01, 5.000e+02],\n",
       "       [5.000e-02, 8.000e-04, 1.000e+01, 5.000e+02],\n",
       "       [5.000e-02, 5.120e-02, 1.000e+00, 5.000e+02],\n",
       "       [1.000e-02, 8.000e-04, 1.000e+01, 2.500e+03],\n",
       "       [1.000e-02, 8.000e-04, 1.000e+01, 1.000e+02],\n",
       "       [2.500e-01, 8.000e-04, 1.000e-02, 1.000e+02],\n",
       "       [1.000e-01, 2.000e-04, 1.000e-01, 2.500e+03],\n",
       "       [1.000e-02, 3.200e-03, 1.000e-01, 2.500e+03],\n",
       "       [2.500e-01, 1.280e-02, 1.000e+01, 2.500e+03],\n",
       "       [5.000e-02, 5.120e-02, 1.000e+01, 2.500e+03],\n",
       "       [1.000e-02, 1.280e-02, 1.000e+01, 5.000e+02],\n",
       "       [1.000e-01, 1.280e-02, 1.000e-01, 2.500e+03],\n",
       "       [5.000e-02, 2.000e-04, 1.000e+01, 5.000e+02],\n",
       "       [1.000e-01, 2.048e-01, 1.000e+00, 2.500e+03],\n",
       "       [1.000e-01, 2.000e-04, 1.000e+00, 5.000e+02],\n",
       "       [5.000e-02, 3.200e-03, 1.000e-01, 2.500e+03],\n",
       "       [1.000e-02, 2.048e-01, 1.000e+01, 2.500e+03],\n",
       "       [2.500e-01, 2.048e-01, 1.000e-02, 5.000e+02],\n",
       "       [2.500e-01, 8.000e-04, 1.000e-01, 2.500e+03],\n",
       "       [1.000e-02, 2.000e-04, 1.000e+00, 1.000e+02],\n",
       "       [1.000e-01, 3.200e-03, 1.000e+01, 2.500e+03],\n",
       "       [5.000e-02, 5.120e-02, 1.000e-02, 1.000e+02],\n",
       "       [1.000e-01, 2.048e-01, 1.000e-02, 5.000e+02],\n",
       "       [2.500e-01, 8.000e-04, 1.000e+00, 1.000e+02],\n",
       "       [1.000e-01, 5.120e-02, 1.000e-01, 2.500e+03],\n",
       "       [1.000e-02, 8.000e-04, 1.000e-02, 2.500e+03],\n",
       "       [2.500e-01, 2.000e-04, 1.000e+00, 2.500e+03],\n",
       "       [5.000e-02, 8.000e-04, 1.000e-02, 1.000e+02],\n",
       "       [5.000e-02, 2.000e-04, 1.000e+01, 2.500e+03],\n",
       "       [1.000e-02, 2.000e-04, 1.000e-01, 1.000e+02],\n",
       "       [1.000e-02, 3.200e-03, 1.000e-01, 5.000e+02],\n",
       "       [2.500e-01, 8.000e-04, 1.000e+01, 1.000e+02],\n",
       "       [5.000e-02, 1.280e-02, 1.000e-01, 2.500e+03],\n",
       "       [5.000e-02, 2.048e-01, 1.000e+00, 1.000e+02],\n",
       "       [5.000e-02, 2.048e-01, 1.000e+00, 5.000e+02],\n",
       "       [5.000e-02, 8.000e-04, 1.000e+00, 2.500e+03],\n",
       "       [1.000e-02, 5.120e-02, 1.000e+01, 5.000e+02],\n",
       "       [1.000e-01, 2.000e-04, 1.000e-02, 2.500e+03],\n",
       "       [5.000e-02, 5.120e-02, 1.000e+01, 5.000e+02],\n",
       "       [1.000e-01, 3.200e-03, 1.000e-01, 2.500e+03],\n",
       "       [5.000e-02, 2.048e-01, 1.000e-01, 2.500e+03],\n",
       "       [1.000e-01, 2.048e-01, 1.000e+01, 5.000e+02],\n",
       "       [1.000e-01, 1.280e-02, 1.000e-02, 2.500e+03],\n",
       "       [1.000e-02, 1.280e-02, 1.000e+01, 2.500e+03],\n",
       "       [1.000e-01, 3.200e-03, 1.000e+00, 1.000e+02],\n",
       "       [2.500e-01, 2.048e-01, 1.000e+01, 1.000e+02],\n",
       "       [1.000e-02, 3.200e-03, 1.000e-02, 2.500e+03],\n",
       "       [5.000e-02, 5.120e-02, 1.000e-02, 2.500e+03],\n",
       "       [5.000e-02, 8.000e-04, 1.000e-02, 2.500e+03],\n",
       "       [1.000e-02, 2.000e-04, 1.000e+00, 2.500e+03],\n",
       "       [1.000e-01, 2.000e-04, 1.000e+01, 2.500e+03],\n",
       "       [1.000e-02, 8.000e-04, 1.000e+00, 2.500e+03],\n",
       "       [2.500e-01, 1.280e-02, 1.000e-01, 5.000e+02],\n",
       "       [1.000e-01, 1.280e-02, 1.000e+00, 2.500e+03],\n",
       "       [1.000e-02, 2.000e-04, 1.000e+01, 5.000e+02],\n",
       "       [1.000e-02, 3.200e-03, 1.000e+00, 1.000e+02],\n",
       "       [1.000e-01, 8.000e-04, 1.000e+00, 5.000e+02],\n",
       "       [1.000e-02, 8.000e-04, 1.000e+00, 5.000e+02],\n",
       "       [1.000e-01, 1.280e-02, 1.000e+01, 2.500e+03],\n",
       "       [5.000e-02, 5.120e-02, 1.000e-01, 5.000e+02],\n",
       "       [2.500e-01, 1.280e-02, 1.000e+01, 1.000e+02],\n",
       "       [1.000e-01, 2.000e-04, 1.000e+00, 2.500e+03],\n",
       "       [2.500e-01, 2.000e-04, 1.000e-01, 2.500e+03],\n",
       "       [5.000e-02, 3.200e-03, 1.000e-02, 5.000e+02],\n",
       "       [1.000e-01, 2.048e-01, 1.000e-01, 1.000e+02],\n",
       "       [2.500e-01, 3.200e-03, 1.000e-01, 1.000e+02],\n",
       "       [1.000e-01, 5.120e-02, 1.000e+01, 2.500e+03],\n",
       "       [2.500e-01, 3.200e-03, 1.000e+00, 2.500e+03],\n",
       "       [1.000e-02, 8.000e-04, 1.000e-01, 2.500e+03],\n",
       "       [5.000e-02, 2.048e-01, 1.000e+00, 2.500e+03],\n",
       "       [5.000e-02, 3.200e-03, 1.000e+01, 5.000e+02],\n",
       "       [5.000e-02, 1.280e-02, 1.000e+00, 2.500e+03],\n",
       "       [1.000e-02, 2.000e-04, 1.000e-02, 1.000e+02],\n",
       "       [2.500e-01, 5.120e-02, 1.000e+00, 1.000e+02],\n",
       "       [5.000e-02, 2.048e-01, 1.000e+01, 2.500e+03],\n",
       "       [2.500e-01, 1.280e-02, 1.000e+00, 1.000e+02],\n",
       "       [2.500e-01, 8.000e-04, 1.000e+01, 5.000e+02],\n",
       "       [5.000e-02, 3.200e-03, 1.000e+00, 5.000e+02],\n",
       "       [1.000e-02, 2.000e-04, 1.000e+00, 5.000e+02],\n",
       "       [5.000e-02, 3.200e-03, 1.000e-01, 1.000e+02],\n",
       "       [1.000e-01, 8.000e-04, 1.000e+00, 2.500e+03],\n",
       "       [1.000e-02, 2.048e-01, 1.000e-02, 2.500e+03],\n",
       "       [2.500e-01, 8.000e-04, 1.000e+01, 2.500e+03],\n",
       "       [5.000e-02, 3.200e-03, 1.000e+01, 1.000e+02],\n",
       "       [5.000e-02, 3.200e-03, 1.000e+01, 2.500e+03],\n",
       "       [2.500e-01, 2.000e-04, 1.000e+00, 5.000e+02],\n",
       "       [5.000e-02, 2.000e-04, 1.000e-01, 5.000e+02],\n",
       "       [5.000e-02, 5.120e-02, 1.000e+00, 1.000e+02],\n",
       "       [2.500e-01, 3.200e-03, 1.000e+01, 1.000e+02],\n",
       "       [1.000e-02, 1.280e-02, 1.000e+00, 2.500e+03],\n",
       "       [1.000e-02, 5.120e-02, 1.000e+01, 2.500e+03],\n",
       "       [5.000e-02, 2.048e-01, 1.000e-01, 5.000e+02],\n",
       "       [5.000e-02, 1.280e-02, 1.000e-01, 1.000e+02],\n",
       "       [1.000e-02, 5.120e-02, 1.000e-02, 5.000e+02],\n",
       "       [2.500e-01, 2.048e-01, 1.000e+00, 5.000e+02],\n",
       "       [1.000e-02, 2.000e-04, 1.000e-01, 2.500e+03],\n",
       "       [5.000e-02, 1.280e-02, 1.000e-02, 2.500e+03],\n",
       "       [1.000e-01, 5.120e-02, 1.000e-02, 1.000e+02],\n",
       "       [2.500e-01, 2.000e-04, 1.000e-01, 5.000e+02],\n",
       "       [2.500e-01, 3.200e-03, 1.000e-01, 2.500e+03],\n",
       "       [2.500e-01, 2.048e-01, 1.000e+01, 5.000e+02],\n",
       "       [5.000e-02, 2.048e-01, 1.000e-02, 1.000e+02],\n",
       "       [1.000e-02, 1.280e-02, 1.000e-01, 5.000e+02],\n",
       "       [5.000e-02, 2.000e-04, 1.000e-01, 1.000e+02],\n",
       "       [5.000e-02, 8.000e-04, 1.000e-01, 1.000e+02],\n",
       "       [1.000e-02, 2.048e-01, 1.000e-01, 1.000e+02],\n",
       "       [1.000e-02, 2.000e-04, 1.000e+01, 2.500e+03]]), target=array([0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 1, 0, 1, 0, 0, 0, 2, 2, 0,\n",
       "       0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       2, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       2, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Specify that all features have real-value numeric data\n",
    "feature_columns = [tf.feature_column.numeric_column('x', shape=[4])]\n",
    "\n",
    "#Define the training and test input functions\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(x={'x': np.array(training_set.data)}, \n",
    "                                                    y=np.array(training_set.target), \n",
    "                                                    num_epochs=1000, \n",
    "                                                    shuffle=True)\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(x={'x': np.array(test_set.data)}, \n",
    "                                                    y=np.array(test_set.target), \n",
    "                                                    num_epochs=1, \n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns, \n",
    "                                        hidden_units=[20,20,20], \n",
    "                                        dropout=0.01,    \n",
    "                                        n_classes=3, \n",
    "                                        optimizer=tf.train.ProximalAdagradOptimizer(learning_rate=0.001,\n",
    "                                                                                    l1_regularization_strength=10.0),\n",
    "                                        activation_fn=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.train(input_fn=train_input_fn, steps=1000)\n",
    "classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
